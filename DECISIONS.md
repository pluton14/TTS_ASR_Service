# Технические решения

## Выбор моделей

### TTS: gTTS
**Почему:** Простота интеграции, хорошее качество, работает без GPU.

**Проблемы:** Требует интернет, возвращает MP3 (нужна конвертация в WAV).

**Альтернативы:** 
- `pyttsx3` - не работает в Docker без звуковой системы
- `espeak` - низкое качество

### ASR: Whisper base.en
**Почему:** Лучшее качество распознавания, работает офлайн после загрузки.

**Проблемы:** Большой размер модели (139MB), долгая загрузка.

**Альтернативы:**
- `tiny.en` - быстрее, но хуже качество
- `small.en` - компромисс между скоростью и качеством

## Что не заработало из коробки

### 1. pyttsx3 в Docker
**Проблема:** Не работает без звуковой системы X11/ALSA.

**Решение:** Заменили на gTTS с конвертацией MP3→WAV через pydub.

### 2. Raw PCM в ASR
**Проблема:** Whisper ожидает WAV файлы, а мы отправляли raw PCM.

**Решение:** Изменили `asr_engine.py` для обработки raw PCM данных:
```python
audio_data = np.frombuffer(audio_bytes, dtype=np.int16)
audio_data = audio_data.astype(np.float32) / 32768.0
```

### 3. Pydantic v2 совместимость
**Проблема:** `BaseSettings` перенесен в `pydantic-settings`.

**Решение:** Обновили импорты и конфигурацию во всех сервисах.

### 4. Exception handlers в FastAPI
**Проблема:** Возвращали Pydantic модели вместо Response объектов.

**Решение:** Заменили на `JSONResponse` с правильными статус-кодами.

### 5. WebSocket timeout в клиенте
**Проблема:** Клиент зависал при проблемах с соединением.

**Решение:** Добавили таймауты и обработку ошибок.

## Архитектурные решения

### Микросервисы vs Монолит
**Выбор:** Микросервисы для независимого масштабирования TTS/ASR.

### HTTP vs WebSocket для TTS
**HTTP:** Простота, chunked streaming.
**WebSocket:** Реальное время, но сложнее.

**Решение:** Поддержка обоих протоколов.

### Передача распознанного текста
**Проблема:** Как передать ASR результат через streaming TTS?

**Решение:** HTTP заголовки `X-Recognized-Text` и `X-Segments`.

## Производительность

- **ASR:** ~2-3 сек на фразу (зависит от длины)
- **TTS:** ~1-2 сек на фразу  
- **Общее время pipeline:** ~3-5 сек

**Оптимизации:**
- Кэширование загруженных моделей
- Параллельная обработка в Gateway
- Chunked streaming для больших аудио
